#!/usr/bin/env python3
import icedbProgSetup  # noqa: F401
import os
import argparse
from pycbio.sys import fileOps, typeOps, loggingOps
from gencode_icedb.general.dataOps import outCnv
import urllib
import requests  # from pip
import json

encodeUrl = "https://www.encodeproject.org/"
encodeSearchUrl = urllib.parse.urljoin(encodeUrl, "/search/")


def parseArgs():
    desc = """query the encode DCC"""
    parser = argparse.ArgumentParser(description=desc)
    loggingOps.addCmdOptions(parser)
    parser.add_argument('--fakeResponse',
                        help="""for testing use this response instead of querying server""")
    parser.add_argument('--response',
                        help="""save response JSON to this file""")
    parser.add_argument('--minReadLength', type=int, default=0,
                        help="""minimum read length to include""")
    parser.add_argument('--limit', default="all",
                        help="""limit on the number of responses to include (for testing)""")
    parser.add_argument('scientificName',
                        help="""scientific name of orgnaism""")
    parser.add_argument('selectedTsv',
                        help="""save response here for later loading into database""")
    parser.add_argument('selectedUrls',
                        help="""URLs for downloading written to this file""")
    opts = parser.parse_args()
    loggingOps.setupFromCmd(opts)
    return opts


selectedTsvHeader = ("runname", "organism", "tissue", "description",
                     "readsfileurl", "readsfile", "md5sum", "readlength",
                     "readsfile2url", "readsfile2", "md5sum2")


def buildUrl(scientificName, limit):
    args = {"type": "Experiment",
            "assay_term_name": "RNA-seq",
            "files.run_type": "paired-ended",
            "status": "released",
            "replicates.library.nucleic_acid_term_name": "polyadenylated mRNA",
            "replicates.library.biosample.donor.organism.scientific_name": scientificName,
            "files.file_type": "fastq",
            "limit": str(limit),
            "frame": "embedded"}
    return "{}?{}".format(encodeSearchUrl, urllib.parse.urlencode(args))


def search(scientificName, limit):
    headers = {'accept': 'application/json'}
    url = buildUrl(scientificName, limit)
    response = requests.get(url, headers=headers)
    return response.json()


def loadFromJson(fname):
    # FIXME use a JSON to object reader??
    with open(fname, "r") as fh:
        return json.load(fh)


def saveToJson(fname, obj):
    with open(fname, "w") as fh:
        json.dump(obj, fh, indent=4, separators=(',', ': '))


def getValue(data, keys):
    "get value from JSON derived object given a tuple of keys"
    if len(keys) == 1:
        return data[keys[0]]
    else:
        return getValue(data[keys[0]], keys[1:])


def findPair(frec1, filesById):
    "returns (frec1, frec2) or (frec1, None)"
    if "paired_end" in frec1:
        # return order paired-ends
        frec2 = filesById[frec1["paired_with"]]
        if frec1["paired_end"] == "1":
            return (frec1, frec2)
        else:
            return (frec2, frec1)
    else:
        return (frec1, None)


def collectFile(frec, filesById, doneIds):
    frec1, frec2 = findPair(frec, filesById)
    doneIds.add(frec1["@id"])
    if frec2 is not None:
        doneIds.add(frec2["@id"])
    runname = frec1["title"]  # just use first
    readsfileurl = urllib.parse.urljoin(encodeUrl, frec1["href"])
    readsfile = os.path.basename(frec1["href"])
    readlength = frec1["read_length"]
    md5sum = frec1["md5sum"]
    if frec2 is not None:
        readsfile2url = urllib.parse.urljoin(encodeUrl, frec2["href"])
        readsfile2 = os.path.basename(frec2["href"])
        md5sum2 = frec2["md5sum"]
    else:
        readsfile2url = readsfile2 = md5sum2 = None
    return typeOps.annon(runname=runname,
                         readsfileurl=readsfileurl,
                         readsfile=readsfile,
                         md5sum=md5sum,
                         readsfile2url=readsfile2url,
                         readsfile2=readsfile2,
                         md5sum2=md5sum2,
                         readlength=readlength)


def useFile(frec, minReadLength, doneIds):
    return ((frec["@id"] not in doneIds) and (frec["file_type"] == "fastq")
            and (frec["read_length"] >= minReadLength))


def collectFastqs(fileRecs, minReadLength):
    "pull data from files array"
    filesById = {frec["@id"]: frec for frec in fileRecs}
    doneIds = set()
    fastqRecs = []
    for frec in fileRecs:
        if useFile(frec, minReadLength, doneIds):
            fastqRecs.append(collectFile(frec, filesById, doneIds))
    return fastqRecs


def collectMetadata(expr):
    replicate = expr["replicates"][0]
    return typeOps.annon(
        organism=getValue(replicate, ("library", "biosample", "organism", "name")),
        tissue=getValue(replicate, ("library", "biosample", "biosample_ontology", "term_name")),
        description=expr["description"])


def processExpr(expr, minReadLength, selectedTsvFh, selectedUrlsFh):
    metadata = collectMetadata(expr)
    fastqs = collectFastqs(expr["files"], minReadLength)

    for fastq in fastqs:
        fileOps.prRowv(selectedTsvFh, fastq.runname, metadata.organism, metadata.tissue,
                       metadata.description, fastq.readsfileurl, fastq.readsfile, fastq.md5sum,
                       fastq.readlength, outCnv(fastq.readsfile2url),
                       outCnv(fastq.readsfile2), outCnv(fastq.md5sum2))
        fileOps.prRowv(selectedUrlsFh, fastq.readsfileurl)
        if fastq.readsfile2url is not None:
            fileOps.prRowv(selectedUrlsFh, fastq.readsfile2url)


def processExprs(response, minReadLength, selectedTsvFh, selectedUrlsFh):
    fileOps.prRow(selectedTsvFh, selectedTsvHeader)
    # we call each thing under @graph an experiment
    for expr in response["@graph"]:
        processExpr(expr, minReadLength, selectedTsvFh, selectedUrlsFh)


def encodeDccQuery(opts):
    if opts.fakeResponse is not None:
        response = loadFromJson(opts.fakeResponse)
    else:
        response = search(opts.scientificName, opts.limit)
    if opts.response is not None:
        saveToJson(opts.response, response)
    with open(opts.selectedTsv, "w") as selectedTsvFh, open(opts.selectedUrls, "w") as selectedUrlsFh:
        processExprs(response, opts.minReadLength, selectedTsvFh, selectedUrlsFh)


encodeDccQuery(parseArgs())
