#!/usr/bin/env python3
import icedbProgSetup  # noqa: F401
import argparse
import csv
from pycbio.sys import fileOps, setOps
from pycbio.hgdata.coords import Coords
from pycbio.hgdata.hgLite import hgSqliteConnect, GencodeAttrsDbTable
from gencode_icedb.general import gencodeDb
from gencode_icedb.general.genome import GenomeReaderFactory
from gencode_icedb.general.transFeatures import IntronFeature
from gencode_icedb.general.annotFeatures import AnnotationFeatures
from gencode_icedb.rsl.rslModel import sqliteConnect, SjSupportReader
from gencode_icedb.rsl.intronSupportCounter import IntronSupportCounter


def parseArgs():
    desc = """Collect novel splice sites evidence for a chromosome range
    (window) that are not in GENCODE annotations.  If intron is within an
    existing gene, report that geneId.  If an putative intron is not
    completely in the window into the chromosome, it will only be processed if
    window contains the first bases of the intron.  This allows generating
    contiguous, non-overlapping regions.
    """
    parser = argparse.ArgumentParser(description=desc)
    GenomeReaderFactory.addCmdOptions(parser)
    parser.add_argument("--minUniqueMapped", type=int, default=0,
                        help="""Minimum number of uniquely mapped reads to call as novel""")
    parser.add_argument('gencodeDb',
                        help="""GENCODE sqlite3 database from gencodeDbLoad""")
    parser.add_argument('sjDb',
                        help="""splice junction evidence sqlite3 database, a correspond *.sjsup.gz and tabix index file must exist""")
    parser.add_argument('resultsTsv',
                        help="""TSV file for results""")
    parser.add_argument('chromRange',
                        help="""zero-based chromosome range, in the form chr:start-end.""")
    return parser.parse_args()


resultsHeader = ("chrom", "intronStart", "intronEnd", "strand", "intronMotif",
                 "numExprs", "numUniqueMapReads", "numMultiMapReads", "geneIds")


class NovelFinder(object):
    def __init__(self, gencodeConn, sjConn, genomeReader, minUniqueMapped):
        self.attrsDbTable = GencodeAttrsDbTable(gencodeConn, gencodeDb.gencode_attrs_table)
        self.attrsCache = dict()  # by transcriptId
        self.sjSupportReader = SjSupportReader(sjDbConn=sjConn)
        self.genomeReader = genomeReader
        self.minUniqueMapped = minUniqueMapped

        # genes are counts for range
        self.rangeTranscripts = None
        self.rangeSupportCnts = IntronSupportCounter(genomeReader)

    def __loadRangeSupport(self, genomeCoords):
        # only use ones that start in this window
        for sjSupp in self.sjSupportReader.fetch(genomeCoords.name, genomeCoords.start, genomeCoords.end):
            if (sjSupp.strand in ('+', '-')) and (genomeCoords.start <= sjSupp.chromStart) and (sjSupp.chromStart < genomeCoords.end):
                self.rangeSupportCnts.sumSjSupp(sjSupp)

    def __loadRangeTranscripts(self, genomeCoords):
        self.rangeTranscripts = AnnotationFeatures.dbFactory(self.attrsDbTable.conn, gencodeDb.gencode_ann_table,
                                                             genomeCoords.name, genomeCoords.start, genomeCoords.end, self.genomeReader)

    def __getOverlappingTrans(self, intron):
        return list(self.rangeTranscripts.transcriptsByRange.overlapping(intron.chrom, intron.chromStart, intron.chromEnd, intron.strand))

    def __haveIntron(self, intron, trans):
        # already strand-filtered
        for feat in trans.features:
            if (isinstance(feat, IntronFeature) and (intron.chromStart == feat.chrom.start)
                and (intron.chromEnd == feat.chrom.end)):
                return True
        return False

    def __anyHaveIntron(self, intron, overlappingTranses):
        for trans in overlappingTranses:
            if self.__haveIntron(intron, trans):
                return True
        return False

    def __getTransAttrs(self, transcriptId):
        attrs = self.attrsCache.get(transcriptId)
        if attrs is None:
            self.attrsCache[transcriptId] = attrs = self.attrsDbTable.getByTranscriptId(transcriptId)
        return attrs

    def __getContainingGenes(self, intron, overlappingTranses):
        geneIds = set()
        for trans in overlappingTranses:
            geneIds.add(self.__getTransAttrs(trans.rna.name).geneId)
        return geneIds

    def __reportNovel(self, intron, sjCounts, overlappingTranses, resultsWriter):
        geneIds = self.__getContainingGenes(intron, overlappingTranses)
        resultsWriter.writerow([intron.chrom, intron.chromStart, intron.chromEnd,
                                intron.strand, intron.intronMotif,
                                sjCounts.numExprs,
                                sjCounts.numUniqueMapReads,
                                sjCounts.numMultiMapReads,
                                setOps.setJoin(geneIds, ",")])

    def __analyzeSj(self, intron, sjCounts, resultsWriter):
        overlappingTranses = self.__getOverlappingTrans(intron)
        if not self.__anyHaveIntron(intron, overlappingTranses):
            self.__reportNovel(intron, sjCounts, overlappingTranses, resultsWriter)

    def __analyzeRange(self, resultsWriter):
        for intron in sorted(self.rangeSupportCnts.keys()):
            if intron.strand in ('+', '-'):
                sjCounts = self.rangeSupportCnts[intron]
                if sjCounts.numUniqueMapReads >= self.minUniqueMapped:
                    self.__analyzeSj(intron, sjCounts, resultsWriter)

    def collectNovel(self, genomeCoords, resultsWriter):
        self.__loadRangeSupport(genomeCoords)
        self.__loadRangeTranscripts(genomeCoords)
        resultsWriter.writerow(resultsHeader)
        self.__analyzeRange(resultsWriter)


def rslGencodeCollectNovel(opts):
    "entry point"
    genomeCoords = Coords.parse(opts.chromRange)
    genomeReader = GenomeReaderFactory.factoryFromCmdOptions(opts).obtain()

    gencodeConn = hgSqliteConnect(opts.gencodeDb, readOnly=True)
    sjConn = sqliteConnect(opts.sjDb, readonly=True)
    novelFinder = NovelFinder(gencodeConn, sjConn, genomeReader, opts.minUniqueMapped)

    fileOps.ensureFileDir(opts.resultsTsv)
    resultsTmpTsv = fileOps.atomicTmpFile(opts.resultsTsv)
    with open(resultsTmpTsv, "w") as fh:
        novelFinder.collectNovel(genomeCoords, csv.writer(fh, dialect=csv.excel_tab,
                                                          lineterminator='\n'))
    fileOps.atomicInstall(resultsTmpTsv, opts.resultsTsv)
    gencodeConn.close()
    if not sjConn.is_closed():  # FIXME: not sure why it is in the is_closed state, maybe lazy open?
        sjConn.close()


rslGencodeCollectNovel(parseArgs())
