#!/usr/bin/env python3

from __future__ import print_function
import icedbProgSetup  # noqa: F401
import os
import argparse
from pycbio.sys import fileOps
from pycbio.tsv import TsvReader
from gencode_icedb.rsl.rslModel import sqliteConnect, GencodeNovel

bulk_size = 75   # size of each bulk insert

# FIXME: duplicated code with rslGencodeCollectSupportFinishJobs


def parseArgs():
    desc = """Combine rslGencodeCollectNovel job results."""
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument('workDir',
                        help="""directory contains results directory""")
    parser.add_argument('resultsDb',
                        help="""Sqlite database were results are stored."""
                        """This does not append results, existing gencodenovel table is dropped.""")
    return parser.parse_args()


resultsTsvTypeMap = {
    "intronStart": int,
    "intronEnd": int,
    "numUniqueMapReads": int,
    "numMultiMapReads": int}


def resultsDbLoad(resultsConn, recs):
    with resultsConn.atomic():
        for idx in range(0, len(recs), bulk_size):
            GencodeNovel.insert_many(recs[idx:idx + bulk_size]).execute()


def rowToDict(row):
    rowdict = {}
    for col in row._columns_:
        rowdict[col] = getattr(row, col)
    return rowdict


def loadResultsTsv(resultsTsv):
    return [rowToDict(row) for row in TsvReader(resultsTsv, typeMap=resultsTsvTypeMap)]


def collectResults(resultsConn, expectedTsvs):
    recs = []
    for resultsTsv in expectedTsvs:
        recs.extend(loadResultsTsv(resultsTsv))
    resultsDbLoad(resultsConn, recs)


def rslGencodeCollectNovelMkJobs(opts):
    "main function"

    fileOps.ensureFileDir(opts.resultsDb)
    resultsConn = sqliteConnect(opts.resultsDb)
    GencodeNovel.drop_table(fail_silently=True)
    GencodeNovel.create_table()
    expectedTsvs = fileOps.readFileLines(os.path.join(opts.workDir, "expected.lst"))
    collectResults(resultsConn, expectedTsvs)
    resultsConn.close()


rslGencodeCollectNovelMkJobs(parseArgs())
