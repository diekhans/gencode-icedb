#!/usr/bin/env python

from __future__ import print_function
import icedbProgSetup  # noqa: F401
import os
import sys
import argparse
from shutil import copyfile
from pycbio.sys import fileOps, loggingOps
from gencode_icedb import dataOps
import logging
import pipettor


def parseArgs():
    desc = """Map reads to a genome with annotations and save splice junction mapping
    information,"""
    parser = argparse.ArgumentParser(description=desc)
    loggingOps.addCmdOptions(parser)
    parser.add_argument('--numThreads', type=int,
                        help="number of threads to use")
    parser.add_argument('--tmpDir',
                        help="""temporary directory to use; a directory with a unique name is created under here and removed after.  Defaults to value of TMPDIR""")
    parser.add_argument('genomeDir',
                        help="""directory to contain all the generated files;
                        this must not exist; Log.out is also saved in this directory""")
    parser.add_argument('readsFile',
                        help="""input reads in SAM, BAM or Fastq format, which maybe compressed""")
    parser.add_argument('--readsFile2',
                        help="""second reads file, used when read pairs are
                        split into two fastq files.  Both reads must be fastq
                        files if used.""")
    parser.add_argument('sjOut',
                        help="""splice junction output file """)
    opts = parser.parse_args()
    loggingOps.setupFromCmd(opts, sys.argv[0])
    if opts.readsFile2 is not None:
        if not (dataOps.isFastq(opts.readsFile) and dataOps.isFastq(opts.readsFile2)):
            parser.error("both reads files must be fastq if --readsFile2 is specified")
    return opts


def starCmd(numThreads, genomeDir, readsFile, readsFile2,
            decompressCmd, starTmpDir, outputTmpDir):
    "construct command line to run STAR"
    cmd = ["STAR",
           "--runMode", "alignReads",
           "--runThreadN", numThreads,
           "--outSAMmode", "None",
           "--genomeDir", genomeDir,
           "--outTmpDir", starTmpDir,
           "--outFileNamePrefix", outputTmpDir + "/",
           "--readFilesIn", readsFile]
    if readsFile2 is not None:
        cmd.append(readsFile2)
    if decompressCmd is not None:
        cmd.extend(["--readFilesCommand", decompressCmd])
    return cmd


def buildStarPipeline(genomeDir, readsFile, readsFile2, numThreads, tmpDir,
                      outputTmpDir):
    # Input depends on if one or two files are specified.  with one file, we
    # pipe it and can read from SAM/BAM.  With two, we need parallel fastq
    # files for paired-end reads.
    cmds = []
    if readsFile2 is None:
        cmds.append(dataOps.getReadsCatCommand(readsFile))
        readsFile = "/dev/stdin"
        decompressCmd = None
    else:
        decompressCmd = fileOps.decompressCmd(readsFile, None)
    cmds.append(starCmd(numThreads, genomeDir, readsFile, readsFile2,
                        decompressCmd, dataOps.getNewTmpDir(tmpDir),
                        outputTmpDir))
    return cmds


def spliceJunctionMap(genomeDir, readsFile, readsFile2, sjOut, numThreads, tmpDir):
    # holds output files before filtering
    outputTmpDir = fileOps.tmpDirGet(prefix="starout", tmpDir=tmpDir)
    fileOps.ensureDir(outputTmpDir)
    sjTmpOut = os.path.join(outputTmpDir, "SJ.out.tab")

    cmds = buildStarPipeline(genomeDir, readsFile, readsFile2, numThreads, tmpDir, outputTmpDir)
    pipettor.run(cmds, logger=logging.getLogger())
    fileOps.ensureFileDir(sjOut)
    sjOutFinalTmp = fileOps.atomicTmpFile(sjOut)
    copyfile(sjTmpOut, sjOutFinalTmp)
    fileOps.atomicInstall(sjOutFinalTmp, sjOut)
    fileOps.rmTree(outputTmpDir)


def starSpliceJunctionMap(opts):
    spliceJunctionMap(opts.genomeDir, opts.readsFile, opts.readsFile2,
                      opts.sjOut, opts.numThreads, opts.tmpDir)


starSpliceJunctionMap(parseArgs())
