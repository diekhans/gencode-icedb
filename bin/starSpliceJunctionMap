#!/usr/bin/env python

import sys
import os
import argparse
from shutil import copyfile
sys.path.insert(0, os.path.expanduser("~markd/compbio/code/pycbio/lib"))
myBinDir = os.path.normpath(os.path.dirname(sys.argv[0]))
sys.path.append(myBinDir + "/../lib")
from pycbio.sys import fileOps
from gencode_icedb import dataOps, pipelineOps

verbose = False
def parseArgs():
    desc = """Map reads to a genome with annotations and save splice junction mapping
    information,"""
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument('--numThreads', type=int,
                        help="number of threads to use")
    parser.add_argument('--verbose', action="store_true", default=False,
                        help="write verbose output")
    parser.add_argument('--tmpDir',
                        help="""temporary directory to use; a directory with a unique name is created under here and removed after.  Defaults to value of TMPDIR""")
    parser.add_argument('genomeDir',
                        help="""directory to contain all the generated files;
                        this must not exist; Log.out is also saved in this directory""")
    parser.add_argument('readsFile',
                        help="""input reads in SAM, BAM or Fastq format, which maybe compressed""")
    parser.add_argument('--readsFile2',
                        help="""second reads file, used when read pairs are
                        split into two fastq files.  Both reads must be fastq
                        files if used.""")
    parser.add_argument('sjOut',
                        help="""splice junction output file """)
    opts = parser.parse_args()
    global verbose
    verbose = opts.verbose
    if opts.readsFile2 is not None:
        if not (dataOps.isFastq(opts.readsFile) and dataOps.isFastq(opts.readsFile2)):
            parser.error("both reads files must be fastq if --readsFile2 is specified")
    return opts

def starCmd(numThreads, genomeDir, readsFile, readsFile2,
            decompressCmd, starTmpDir, outputTmpDir):
    "construct command line to run STAR"
    cmd = ["STAR",
           "--runMode", "alignReads",
           "--runThreadN", numThreads,
           "--outSAMmode", "None",
           "--genomeDir", genomeDir,
           "--outTmpDir", starTmpDir,
           "--outFileNamePrefix", outputTmpDir+"/",
           "--readFilesIn", readsFile]
    if readsFile2 is not None:
        cmd.append(readsFile2)
    if decompressCmd is not None:
        cmd.extend(["--readFilesCommand", decompressCmd])
    return cmd

def buildStarPipeline(genomeDir, readsFile, readsFile2, numThreads, tmpDir,
                      outputTmpDir):
    # Input depends on if one or two files are specified.  with one file, we
    # pipe it and can read from SAM/BAM.  With two, we need parallel fastq
    # files for paired-end reads.
    cmds = []
    if readsFile2 == None:
        cmds.append(dataOps.getReadsCatCommand(readsFile))
        readsFile = "/dev/stdin"
        decompressCmd = None
    else:
        decompressCmd = fileOps.decompressCmd(readsFile, None)
    cmds.append(starCmd(numThreads, genomeDir, readsFile, readsFile2,
                        decompressCmd, dataOps.getNewTmpDir(tmpDir),
                        outputTmpDir))
    return cmds

def starSpliceJunctionMap(genomeDir, readsFile, readsFile2, sjOut, numThreads, tmpDir):
    # holds output files before filtering
    outputTmpDir = fileOps.tmpDirGet(prefix="starout", tmpDir=tmpDir)
    fileOps.ensureDir(outputTmpDir)
    sjTmpOut = os.path.join(outputTmpDir, "SJ.out.tab")

    cmds = buildStarPipeline(genomeDir, readsFile, readsFile2, numThreads, tmpDir, outputTmpDir)
    pipelineOps.runCmd(cmds, verbose=verbose)
    fileOps.ensureFileDir(opts.sjOut)
    sjOutFinalTmp = fileOps.atomicTmpFile(sjOut)
    copyfile(sjTmpOut, sjOutFinalTmp)
    fileOps.atomicInstall(sjOutFinalTmp, sjOut)
    fileOps.rmTree(outputTmpDir)

opts = parseArgs()
starSpliceJunctionMap(opts.genomeDir, opts.readsFile, opts.readsFile2,
                      opts.sjOut, opts.numThreads, opts.tmpDir)
